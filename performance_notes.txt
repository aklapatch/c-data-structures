Adding quadratic probes to values searching really sped things up.
I may add a version of cuckoo hashing next (hash the hash to find the 
next slot). (done, not much better than quadratic probing IIRC)
Searching for values still takes a lot of time. (Fixed)
Changing to a version of cuckoo hash makes lookups take longer.
Tried splitting the table into 2 partitions, so that you are looking in
a different section of memory when you find a collision, but that slowed
things down
The hash and hash again probing is much faster than quadratic probing
for insertions From what I can tell. For queries quadratic seems to be a little
better
Tried pre-computing the hashes needed for probing and that made things
slower queries got 100% slower. also, STBs default hash function is
faster than ahash's fallback funcion by a lot margin.
Storing the hash_fn as a local variable seemed to speed things up
significantly
Tried moving the val searching out of the key search main loop and that
didn't slow things down to much. I had to add a way to store the
truncated hashes locally though.
I could try making whether a key slot is taken or not be in another array.
That way a byte could represent 8 slots, and you could check 64*8 slots
per cache line. Searching could use that memor too, but I'm not sure if
it would help or not.

Tried having searches search by bit, and that does not seem to help
Tried adding an another array of bits that has one bit per key slot taken, and that did not help.
Tried seprating the loops that search the lower and upper halves of the buckets and that did not help

I really need a low-latency hash for the hash map with keys, my
implementations of xxhash and ahash are worse than the function provided
by stb I think
Un-optimized, xxhash seems to be significantly faster than ahash's
fallback function.
-O2 for the hash bench skips any hashing whatsoever it only takes 1
clock to do things
Actually, after adding keeping the hashing from getting optimized out,
xxhash seems a lot faster.

For ant hash:
- for some reason, switching the hash bench to not use an array of
  hashes makes it a lot faster. Probably better cache behavior, but I'm
  not sure.
- Making the hash test hash the hash seems to work the best for
  comparison testing. The compiler does not eliminate the other rounds I
  guess

Decided to make ant_hash hash a single uintptr_t, since we don't really need to hash anything else for the key hash table. The dict will be a different story

Ant hash makes the key hash table close enough to the stb hash table. I may still need to try hash caching and see if it's faster, and try caching more keys and indexes before inserting them
I also need to try messing with when the table grows. (a load factor of 2/5 is really bad)

Making the hash function a macro and not a function pointer helps performance a little bit. insertions go from 1.20 ish to 1.16 ish
I think I'm going to leave the realloc fn to be a macro and the hash_fn to be a run-time param. There's not much difference either way, but keeping realloc as a macro allows me to conditionally include stdlib.h, which I like better than checking if it's already included
